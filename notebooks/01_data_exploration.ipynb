{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d8b546",
   "metadata": {},
   "source": [
    "# ğŸ“Š Sales Data Exploration - Your First Pandas Adventure!\n",
    "\n",
    "Welcome to your comprehensive sales data analysis project! This notebook will guide you through exploring e-commerce sales data using pandas.\n",
    "\n",
    "## ğŸ¯ What You'll Learn\n",
    "- Loading and inspecting datasets\n",
    "- Data quality assessment\n",
    "- Basic statistical analysis\n",
    "- Data relationships and patterns\n",
    "- Essential pandas operations\n",
    "\n",
    "## ğŸ“‹ Prerequisites\n",
    "- Basic Python knowledge\n",
    "- Pandas fundamentals (Series, DataFrame, indexing)\n",
    "- Understanding of data types\n",
    "\n",
    "Let's start exploring! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bffc6af",
   "metadata": {},
   "source": [
    "## 1. ğŸ“š Import Required Libraries\n",
    "\n",
    "First, let's import all the libraries we'll need for our data exploration journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# For interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# System libraries\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"ğŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360990e",
   "metadata": {},
   "source": [
    "## 2. ğŸ“ Load Sales Data\n",
    "\n",
    "Now let's load our datasets! We have four related tables:\n",
    "- **Customers**: Customer information and demographics\n",
    "- **Products**: Product catalog with prices and categories  \n",
    "- **Orders**: Order details and shipping information\n",
    "- **Sales**: Individual sale transactions with quantities and prices\n",
    "\n",
    "### ğŸ”§ Practice Tip\n",
    "Before running this cell, make sure you've generated the sample data by running:\n",
    "```bash\n",
    "python data/sample_data_generator.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b04b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data file paths\n",
    "data_path = '../data/raw/'\n",
    "\n",
    "# Load all datasets\n",
    "print(\"ğŸ”„ Loading datasets...\")\n",
    "\n",
    "try:\n",
    "    # Load each dataset\n",
    "    customers_df = pd.read_csv(f'{data_path}customers.csv')\n",
    "    products_df = pd.read_csv(f'{data_path}products.csv')\n",
    "    orders_df = pd.read_csv(f'{data_path}orders.csv')\n",
    "    sales_df = pd.read_csv(f'{data_path}sales.csv')\n",
    "    \n",
    "    print(\"âœ… All datasets loaded successfully!\")\n",
    "    \n",
    "    # Display dataset sizes\n",
    "    print(f\"\\nğŸ“Š Dataset Sizes:\")\n",
    "    print(f\"â”œâ”€â”€ Customers: {len(customers_df):,} records\")\n",
    "    print(f\"â”œâ”€â”€ Products: {len(products_df):,} records\") \n",
    "    print(f\"â”œâ”€â”€ Orders: {len(orders_df):,} records\")\n",
    "    print(f\"â””â”€â”€ Sales: {len(sales_df):,} records\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure to run 'python data/sample_data_generator.py' first!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cddc56",
   "metadata": {},
   "source": [
    "## 3. ğŸ” Data Inspection & Quality Assessment\n",
    "\n",
    "Let's get familiar with our data! We'll examine the structure, data types, and quality of each dataset.\n",
    "\n",
    "### ğŸ¯ Key pandas methods you'll practice:\n",
    "- `.head()` and `.tail()` - Quick data preview\n",
    "- `.info()` - Data types and memory usage\n",
    "- `.describe()` - Statistical summaries\n",
    "- `.shape` - Dataset dimensions\n",
    "- `.columns` - Column names\n",
    "- `.dtypes` - Data types\n",
    "- `.isnull()` - Missing value detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‘¥ CUSTOMERS DATASET EXPLORATION\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ‘¥ CUSTOMERS DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"ğŸ“‹ Basic Info:\")\n",
    "print(f\"Shape: {customers_df.shape}\")\n",
    "print(f\"Columns: {list(customers_df.columns)}\")\n",
    "\n",
    "print(\"\\nğŸ” First 3 records:\")\n",
    "display(customers_df.head(3))\n",
    "\n",
    "print(\"\\nğŸ“Š Data Types & Missing Values:\")\n",
    "display(customers_df.info())\n",
    "\n",
    "print(\"\\nğŸ“ˆ Statistical Summary (numerical columns):\")\n",
    "display(customers_df.describe())\n",
    "\n",
    "print(\"\\nğŸ” Missing Values Check:\")\n",
    "missing_values = customers_df.isnull().sum()\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"âœ… No missing values found!\")\n",
    "\n",
    "print(\"\\nğŸ¯ Customer Segments Distribution:\")\n",
    "print(customers_df['customer_segment'].value_counts())\n",
    "\n",
    "print(\"\\nğŸ‚ Age Group Distribution:\")\n",
    "print(customers_df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ›ï¸ PRODUCTS DATASET EXPLORATION\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ›ï¸ PRODUCTS DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"ğŸ“‹ Basic Info:\")\n",
    "print(f\"Shape: {products_df.shape}\")\n",
    "print(f\"Columns: {list(products_df.columns)}\")\n",
    "\n",
    "print(\"\\nğŸ” First 3 records:\")\n",
    "display(products_df.head(3))\n",
    "\n",
    "print(\"\\nğŸ“Š Data Types:\")\n",
    "print(products_df.dtypes)\n",
    "\n",
    "print(\"\\nğŸ“ˆ Price Statistics:\")\n",
    "display(products_df[['price', 'cost', 'weight_kg', 'rating']].describe())\n",
    "\n",
    "print(\"\\nğŸ·ï¸ Categories Distribution:\")\n",
    "print(products_df['category'].value_counts())\n",
    "\n",
    "print(\"\\nğŸ¯ Price Ranges:\")\n",
    "products_df['price_range'] = pd.cut(products_df['price'], \n",
    "                                   bins=[0, 50, 100, 300, 1000, 3000], \n",
    "                                   labels=['$0-50', '$50-100', '$100-300', '$300-1000', '$1000+'])\n",
    "print(products_df['price_range'].value_counts())\n",
    "\n",
    "print(\"\\nâ­ Rating Distribution:\")\n",
    "print(products_df['rating'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a634e7d",
   "metadata": {},
   "source": [
    "## 4. ğŸ“… Data Cleaning and Preprocessing\n",
    "\n",
    "Time to clean our data and prepare it for analysis! This is where pandas really shines.\n",
    "\n",
    "### ğŸ¯ What we'll do:\n",
    "- Convert date columns to datetime format\n",
    "- Handle any data type issues\n",
    "- Create derived columns for analysis\n",
    "- Merge datasets for comprehensive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§¹ DATA CLEANING & PREPROCESSING\n",
    "\n",
    "print(\"ğŸ§¹ Cleaning and preprocessing data...\")\n",
    "\n",
    "# 1. Convert date columns to datetime\n",
    "print(\"ğŸ“… Converting date columns...\")\n",
    "customers_df['registration_date'] = pd.to_datetime(customers_df['registration_date'])\n",
    "products_df['launch_date'] = pd.to_datetime(products_df['launch_date'])\n",
    "orders_df['order_date'] = pd.to_datetime(orders_df['order_date'])\n",
    "orders_df['shipped_date'] = pd.to_datetime(orders_df['shipped_date'])\n",
    "orders_df['delivered_date'] = pd.to_datetime(orders_df['delivered_date'])\n",
    "\n",
    "# 2. Create a comprehensive sales dataset by merging tables\n",
    "print(\"ğŸ”— Creating comprehensive sales dataset...\")\n",
    "sales_analysis_df = sales_df.merge(orders_df, on='order_id', how='left') \\\n",
    "                           .merge(products_df, on='product_id', how='left') \\\n",
    "                           .merge(customers_df, on='customer_id', how='left')\n",
    "\n",
    "print(f\"âœ… Created comprehensive dataset with {len(sales_analysis_df):,} records\")\n",
    "\n",
    "# 3. Add derived columns for analysis\n",
    "print(\"â• Adding derived columns...\")\n",
    "\n",
    "# Calculate profit margin\n",
    "sales_analysis_df['profit_margin'] = (sales_analysis_df['profit'] / sales_analysis_df['total_amount']) * 100\n",
    "\n",
    "# Extract time-based features\n",
    "sales_analysis_df['year'] = sales_analysis_df['order_date'].dt.year\n",
    "sales_analysis_df['month'] = sales_analysis_df['order_date'].dt.month\n",
    "sales_analysis_df['quarter'] = sales_analysis_df['order_date'].dt.quarter\n",
    "sales_analysis_df['day_of_week'] = sales_analysis_df['order_date'].dt.day_name()\n",
    "sales_analysis_df['month_name'] = sales_analysis_df['order_date'].dt.month_name()\n",
    "\n",
    "# Calculate delivery time\n",
    "sales_analysis_df['delivery_days'] = (sales_analysis_df['delivered_date'] - sales_analysis_df['order_date']).dt.days\n",
    "\n",
    "print(\"âœ… Data preprocessing complete!\")\n",
    "\n",
    "# Display the enhanced dataset\n",
    "print(f\"\\nğŸ“Š Enhanced Sales Dataset:\")\n",
    "print(f\"Shape: {sales_analysis_df.shape}\")\n",
    "print(f\"Date range: {sales_analysis_df['order_date'].min()} to {sales_analysis_df['order_date'].max()}\")\n",
    "\n",
    "display(sales_analysis_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e2a19",
   "metadata": {},
   "source": [
    "## 5. ğŸ“ˆ Summary Statistics & Key Metrics\n",
    "\n",
    "Now let's calculate some key business metrics using pandas aggregation functions!\n",
    "\n",
    "### ğŸ¯ Pandas skills you'll practice:\n",
    "- `.sum()`, `.mean()`, `.count()` - Basic aggregations\n",
    "- `.groupby()` - Group-wise operations  \n",
    "- `.agg()` - Multiple aggregations\n",
    "- `.value_counts()` - Frequency analysis\n",
    "- `.quantile()` - Percentile calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š KEY BUSINESS METRICS\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ’° OVERALL BUSINESS PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall metrics\n",
    "total_revenue = sales_analysis_df['total_amount'].sum()\n",
    "total_profit = sales_analysis_df['profit'].sum()\n",
    "total_orders = sales_analysis_df['order_id'].nunique()\n",
    "total_customers = sales_analysis_df['customer_id'].nunique()\n",
    "total_products_sold = sales_analysis_df['quantity'].sum()\n",
    "avg_order_value = sales_analysis_df.groupby('order_id')['total_amount'].sum().mean()\n",
    "\n",
    "print(f\"ğŸ’µ Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"ğŸ’° Total Profit: ${total_profit:,.2f}\")\n",
    "print(f\"ğŸ“ˆ Profit Margin: {(total_profit/total_revenue)*100:.1f}%\")\n",
    "print(f\"ğŸ›’ Total Orders: {total_orders:,}\")\n",
    "print(f\"ğŸ‘¥ Unique Customers: {total_customers:,}\")\n",
    "print(f\"ğŸ“¦ Total Products Sold: {total_products_sold:,}\")\n",
    "print(f\"ğŸ’³ Average Order Value: ${avg_order_value:.2f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“… TIME-BASED ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Monthly performance\n",
    "monthly_sales = sales_analysis_df.groupby(['year', 'month']).agg({\n",
    "    'total_amount': 'sum',\n",
    "    'profit': 'sum',\n",
    "    'order_id': 'nunique',\n",
    "    'quantity': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "print(\"ğŸ“Š Monthly Sales Summary (Last 6 months):\")\n",
    "display(monthly_sales.tail(6))\n",
    "\n",
    "# Best performing month\n",
    "best_month = sales_analysis_df.groupby('month_name')['total_amount'].sum().sort_values(ascending=False)\n",
    "print(f\"\\nğŸ† Best performing month: {best_month.index[0]} (${best_month.iloc[0]:,.2f})\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ·ï¸ PRODUCT PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Category performance\n",
    "category_performance = sales_analysis_df.groupby('category').agg({\n",
    "    'total_amount': 'sum',\n",
    "    'profit': 'sum',\n",
    "    'quantity': 'sum',\n",
    "    'order_id': 'nunique'\n",
    "}).round(2).sort_values('total_amount', ascending=False)\n",
    "\n",
    "print(\"ğŸ›ï¸ Sales by Category:\")\n",
    "display(category_performance)\n",
    "\n",
    "# Top 10 products by revenue\n",
    "top_products = sales_analysis_df.groupby(['product_id', 'product_name']).agg({\n",
    "    'total_amount': 'sum',\n",
    "    'quantity': 'sum'\n",
    "}).round(2).sort_values('total_amount', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nğŸŒŸ Top 10 Products by Revenue:\")\n",
    "display(top_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b830cfa",
   "metadata": {},
   "source": [
    "## 6. ğŸ“Š Sales Trend Visualization\n",
    "\n",
    "Time to visualize our data! We'll create compelling charts to understand sales patterns and trends.\n",
    "\n",
    "### ğŸ¯ Visualization skills you'll practice:\n",
    "- Line plots for time series trends\n",
    "- Bar charts for categorical comparisons\n",
    "- Heatmaps for correlation analysis\n",
    "- Multiple subplots for comprehensive views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ SALES TREND VISUALIZATIONS\n",
    "\n",
    "# Set up the plotting area\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('ğŸ“Š Sales Performance Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Monthly Revenue Trend\n",
    "monthly_revenue = sales_analysis_df.groupby(sales_analysis_df['order_date'].dt.to_period('M'))['total_amount'].sum()\n",
    "monthly_revenue.plot(kind='line', ax=axes[0,0], marker='o', linewidth=2, markersize=6)\n",
    "axes[0,0].set_title('ğŸ“ˆ Monthly Revenue Trend')\n",
    "axes[0,0].set_ylabel('Revenue ($)')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Daily Sales Pattern (by day of week)\n",
    "daily_pattern = sales_analysis_df.groupby('day_of_week')['total_amount'].sum().reindex([\n",
    "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
    "])\n",
    "daily_pattern.plot(kind='bar', ax=axes[0,1], color='lightcoral')\n",
    "axes[0,1].set_title('ğŸ“… Sales by Day of Week')\n",
    "axes[0,1].set_ylabel('Revenue ($)')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Category Performance\n",
    "category_sales = sales_analysis_df.groupby('category')['total_amount'].sum().sort_values(ascending=True)\n",
    "category_sales.plot(kind='barh', ax=axes[1,0], color='skyblue')\n",
    "axes[1,0].set_title('ğŸ·ï¸ Revenue by Category')\n",
    "axes[1,0].set_xlabel('Revenue ($)')\n",
    "\n",
    "# 4. Customer Segment Analysis\n",
    "segment_sales = sales_analysis_df.groupby('customer_segment')['total_amount'].sum()\n",
    "colors = ['gold', 'lightgreen', 'lightblue']\n",
    "axes[1,1].pie(segment_sales.values, labels=segment_sales.index, autopct='%1.1f%%', \n",
    "              colors=colors, startangle=90)\n",
    "axes[1,1].set_title('ğŸ‘¥ Revenue by Customer Segment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional interactive plot with Plotly\n",
    "print(\"\\nğŸ¯ Interactive Monthly Trend (with Plotly):\")\n",
    "monthly_data = sales_analysis_df.groupby(sales_analysis_df['order_date'].dt.to_period('M')).agg({\n",
    "    'total_amount': 'sum',\n",
    "    'profit': 'sum',\n",
    "    'order_id': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_data['order_date'] = monthly_data['order_date'].astype(str)\n",
    "\n",
    "fig_plotly = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig_plotly.add_trace(\n",
    "    go.Scatter(x=monthly_data['order_date'], y=monthly_data['total_amount'], \n",
    "               name=\"Revenue\", line=dict(color='blue', width=3)),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig_plotly.add_trace(\n",
    "    go.Scatter(x=monthly_data['order_date'], y=monthly_data['order_id'], \n",
    "               name=\"Orders\", line=dict(color='red', width=3)),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "fig_plotly.update_xaxes(title_text=\"Month\")\n",
    "fig_plotly.update_yaxis(title_text=\"Revenue ($)\", secondary_y=False)\n",
    "fig_plotly.update_yaxis(title_text=\"Number of Orders\", secondary_y=True)\n",
    "fig_plotly.update_layout(title_text=\"ğŸ“Š Monthly Revenue & Orders Trend\", height=400)\n",
    "\n",
    "fig_plotly.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce24fd70",
   "metadata": {},
   "source": [
    "## 7. ğŸ¯ Practice Exercises\n",
    "\n",
    "Now it's your turn! Try these exercises to strengthen your pandas skills.\n",
    "\n",
    "### ğŸ”¥ Challenge 1: Customer Analysis\n",
    "Find the top 10 customers by total spending and analyze their purchasing patterns.\n",
    "\n",
    "### ğŸ”¥ Challenge 2: Seasonal Trends  \n",
    "Identify which quarters perform best and create a seasonal analysis.\n",
    "\n",
    "### ğŸ”¥ Challenge 3: Product Insights\n",
    "Calculate the profit margin by product category and find the most profitable products.\n",
    "\n",
    "### ğŸ”¥ Challenge 4: Geographic Analysis\n",
    "Analyze sales performance by state/region (use the customer location data).\n",
    "\n",
    "### ğŸ”¥ Challenge 5: Time-based Patterns\n",
    "Find the best-selling day of the week for each product category.\n",
    "\n",
    "**ğŸ’¡ Tip**: Use the cells below to work on these challenges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10957134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ YOUR PRACTICE SPACE\n",
    "# Use this cell to work on the challenges above!\n",
    "\n",
    "# Example: Challenge 1 - Top 10 customers by total spending\n",
    "print(\"Challenge 1: Top 10 Customers by Total Spending\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "top_customers = sales_analysis_df.groupby(['customer_id', 'first_name', 'last_name']).agg({\n",
    "    'total_amount': 'sum',\n",
    "    'order_id': 'nunique',\n",
    "    'quantity': 'sum'\n",
    "}).round(2).sort_values('total_amount', ascending=False).head(10)\n",
    "\n",
    "display(top_customers)\n",
    "\n",
    "# Add your own analysis below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553e61b",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "You've completed your first comprehensive pandas data exploration! Here's what you've learned:\n",
    "\n",
    "### âœ… Skills Mastered:\n",
    "- **Data Loading**: Reading CSV files with `pd.read_csv()`\n",
    "- **Data Inspection**: Using `.head()`, `.info()`, `.describe()`, `.shape`\n",
    "- **Data Cleaning**: Converting data types, handling dates\n",
    "- **Data Merging**: Combining multiple datasets with `.merge()`\n",
    "- **Aggregation**: Using `.groupby()`, `.sum()`, `.mean()`, `.count()`\n",
    "- **Visualization**: Creating charts with matplotlib and plotly\n",
    "- **Time Series**: Working with datetime data and extracting features\n",
    "\n",
    "### ğŸš€ Next Steps:\n",
    "1. **Advanced Analysis**: Move to `02_data_cleaning.ipynb` for deeper data preprocessing\n",
    "2. **Customer Analytics**: Explore `04_customer_analysis.ipynb` for customer segmentation\n",
    "3. **Dashboard Creation**: Build interactive dashboards in `05_dashboard_creation.ipynb`\n",
    "\n",
    "### ğŸ’¡ Keep Practicing:\n",
    "- Try the challenge exercises above\n",
    "- Experiment with different visualizations\n",
    "- Ask business questions and use pandas to find answers!\n",
    "\n",
    "**Happy Analyzing! ğŸ“Šâœ¨**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
